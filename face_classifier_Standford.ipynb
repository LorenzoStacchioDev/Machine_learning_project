{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from  keras.models import Sequential, Model\n",
    "from  keras.layers import Input,Concatenate, Dense, LeakyReLU,Input, Activation, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, InputLayer, Flatten, BatchNormalization, Reshape, Lambda\n",
    "\n",
    "from  keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from  keras.applications.vgg16 import VGG16, preprocess_input\n",
    "#from  keras.applications import ResNet152V2,ResNet101V2,ResNet50V2 \n",
    "#from  keras.applications.resnet_v2 import preprocess_input \n",
    "\n",
    "from  keras.optimizers import RMSprop, Adam\n",
    "from  keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from  keras.utils import multi_gpu_model\n",
    "from IPython.display import Image \n",
    "\n",
    "import keras_metrics\n",
    "import pandas\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw,ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolf_loss(y_true, y_pred):\n",
    "    #true e pred sono [32][245]\n",
    "    \n",
    "    #tensorflow.print(\"tensors:\", y_pred)\n",
    "    #tensorflow.print(\"batch_size:\", tensorflow.shape(y_pred)[0])\n",
    "    \n",
    "    #y_pred = tensorflow.reshape(y_pred, [tensorflow.shape(y_pred)[0], 7, 7, 5])\n",
    "    #y_true = tensorflow.reshape(y_true, [tensorflow.shape(y_pred)[0], 7, 7, 5])\n",
    "\n",
    "\n",
    "    b_p_pred = y_pred[0]\n",
    "    b_x_pred = y_pred[1]\n",
    "    b_y_pred = y_pred[2]\n",
    "    b_w_pred = y_pred[3]\n",
    "    b_h_pred = y_pred[4]\n",
    "\n",
    "\n",
    "    b_p = y_true[0]\n",
    "    b_x = y_true[1]\n",
    "    b_y = y_true[2]\n",
    "    b_w = y_true[3]\n",
    "    b_h = y_true[4]\n",
    "\n",
    "    #print(b_xy_pred.get_shape(),b_xy.get_shape())\n",
    "    #print(b_wh_pred.get_shape(),b_wh.get_shape())\n",
    "    #indicator_coord = K.expand_dims(y_true[ 3], axis=-1) * 1.0\n",
    "    loss_p = K.sum(K.square(b_p - b_p_pred), axis=-1)\n",
    "    loss_xy = K.sum(b_p * (K.square(b_x - b_x_pred) + K.square(b_y - b_y_pred)), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "    \n",
    "    #b_w = K.pow(b_w, 0.5)\n",
    "    #b_h = K.pow(b_h, 0.5)\n",
    "    #b_w_pred = K.pow(b_w_pred, 0.5)\n",
    "    #b_h_pred = K.pow(b_h_pred, 0.5)\n",
    "    \n",
    "    loss_wh = K.sum(\n",
    "        b_p * \n",
    "        (\n",
    "            (K.square(b_w - b_w_pred)) + \n",
    "            (K.square(b_h - b_h_pred))\n",
    "        ), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "    #tensorflow.print(\"loss_p:\", loss_p)\n",
    "    #tensorflow.print(\"loss_xy:\", loss_xy)\n",
    "    #tensorflow.print(\"loss_wh:\", loss_wh)\n",
    "    #tensorflow.print(\"Loss:\", ( K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\") )/3)\n",
    "    return (K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\"))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocess_input(img):\n",
    "    #print(img)\n",
    "    #print(type(img))\n",
    "    #print(img.shape)\n",
    "    #plt.imshow((img).astype(np.uint8), vmin=0, vmax=255)\n",
    "    #plt.show()\n",
    "    #print(img.shape)\n",
    "    img_pil = Image.fromarray(img.astype(np.uint8)).convert('L')\n",
    "    img = np.array(img_pil)\n",
    "    img = np.repeat(img[..., np.newaxis], 3, -1)\n",
    "    #print(img.shape)\n",
    "    #plt.imshow(img.astype(np.uint8), vmin=0, vmax=255)\n",
    "    #plt.show()\n",
    "    img = img.astype('float64')\n",
    "    img /= 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pandas.read_csv(\"/data01/ML/dataset/FACE_CLASSIFIER/train2.csv\")\n",
    "valid_df = pandas.read_csv(\"/data01/ML/dataset/FACE_CLASSIFIER/val2.csv\")\n",
    "test_df = pandas.read_csv(\"/data01/ML/dataset/FACE_CLASSIFIER/test2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_paths(path_string):\n",
    "    temp = path_string.replace(\"\\\\\", \"/\")  \n",
    "    return \"/data01/ML/\" + temp.split(\"/\",1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_path\"] = train_df[\"image_path\"].apply(convert_paths)\n",
    "valid_df[\"image_path\"] = valid_df[\"image_path\"].apply(convert_paths)\n",
    "test_df[\"image_path\"] = test_df[\"image_path\"].apply(convert_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    #rescale=1./255,\n",
    "    preprocessing_function = custom_preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=None,\n",
    "        x_col=\"image_path\",\n",
    "        y_col=[\"p\",\"x\",\"y\",\"w\",\"h\"],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=None,\n",
    "        x_col=\"image_path\",\n",
    "        y_col=[\"p\",\"x\",\"y\",\"w\",\"h\"],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count = 0\n",
    "for el in train_generator:\n",
    "    count = count +1\n",
    "    image = el[0][0]\n",
    "    classf = el[1][0]\n",
    "    #img_pil = Image.fromarray(image.astype(np.uint8))\n",
    "    print(classf)\n",
    "    plt.imshow(image.astype(np.uint8), vmin=0, vmax=255)\n",
    "    ax = plt.gca()\n",
    "    # Create a Rectangle patch\n",
    "    print(classf[0])\n",
    "    if classf[0]==1:\n",
    "        rect = patches.Rectangle((classf[1] - int(classf[3]/2)\n",
    "                          ,classf[2] - int(classf[4]/2))\n",
    "                         ,classf[3],classf[4],linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "    #print(classf)\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.samples/train_generator.batch_size\n",
    "step_size_valid = valid_generator.samples/valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp =  Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "model = Conv2D(32,3, strides=(1,1), padding = \"same\")(inp)\n",
    "model = LeakyReLU(alpha=0.1)(model)\n",
    "model = MaxPooling2D(pool_size=(2, 2))(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(64,3, strides=(1,1), padding = \"same\")(model)\n",
    "model = LeakyReLU(alpha=0.1)(model)\n",
    "model = MaxPooling2D(pool_size=(2, 2))(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(128,3, strides=(1,1), padding = \"same\")(model)\n",
    "model = LeakyReLU(alpha=0.1)(model)\n",
    "model = MaxPooling2D(pool_size=(2, 2))(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(64,3, strides=(1,1), padding = \"same\")(model)\n",
    "model = LeakyReLU(alpha=0.1)(model)\n",
    "model = MaxPooling2D(pool_size=(2, 2))(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(32,3, strides=(1,1), padding = \"same\")(model)\n",
    "model = LeakyReLU(alpha=0.1)(model)\n",
    "model = MaxPooling2D(pool_size=(2, 2))(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Conv2D(16,3, strides=(1,1), padding = \"same\")(model)\n",
    "model = LeakyReLU(alpha=0.1)(model)\n",
    "#model = MaxPooling2D(pool_size=(2, 2))(model)\n",
    "\n",
    "model = Flatten()(model)\n",
    "\n",
    "#Divide\n",
    "#localization = Dense(128, activation='relu')(model)\n",
    "localization = Dense(4, activation='relu')(localization)\n",
    "\n",
    "classification = Dense(64, activation='relu')(model)\n",
    "classification = Dense(1, activation='relu')(classification)\n",
    "\n",
    "model = Concatenate()([localization, classification])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[inp], outputs=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr = 1e-4), loss=yolf_loss, metrics=[yolf_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = ModelCheckpoint('standford_face_classifier.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "#reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=15, verbose=1, mode='min')\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, epochs=150, steps_per_epoch=step_size_train, validation_data=valid_generator, validation_steps=step_size_valid, verbose=1, callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function = custom_preprocess_input)\n",
    "\n",
    "test_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=None,\n",
    "        x_col=\"image_path\",\n",
    "        y_col=[\"p\",\"x\",\"y\",\"w\",\"h\"],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n / test_generator.batch_size \n",
    "\n",
    "#CHANGE PARALLEL MODEL\n",
    "pred=model.predict_generator(test_generator,steps=STEP_SIZE_TEST, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for el in zip(pred,test_generator.labels,test_generator.filenames):\n",
    "    count = count +1\n",
    "    if el[0][0]==1:\n",
    "        img = Image.open(el[2])\n",
    "        img1 = ImageDraw.Draw(img)\n",
    "        x1,y1 = el[0][1]-(el[0][3]/2),el[0][2]-(el[0][4]/2)\n",
    "        x2,y2 = el[0][1]+(el[0][3]/2),el[0][2]+(el[0][4]/2)\n",
    "        img1.rectangle([(x1,y1),(x2,y2)], outline =\"red\") \n",
    "        img.save(\"./dataset/NUOVO/results/output\"+ str(count) + \".jpg\")\n",
    "        #img.show() \n",
    "    if count == 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
