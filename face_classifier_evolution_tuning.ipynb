{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.client import device_lib\n",
    "from  keras.models import Sequential, Model\n",
    "from  keras.layers import Input, Dense, LeakyReLU, Activation, Concatenate, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, InputLayer, Flatten, BatchNormalization, Reshape, Lambda\n",
    "from  keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau \n",
    "from  keras.optimizers import RMSprop, Adam\n",
    "from  keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from  keras.utils import multi_gpu_model\n",
    "from IPython.display import Image \n",
    "\n",
    "import keras_metrics\n",
    "import pandas\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw,ImageFont\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "#device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolf_loss(y_true, y_pred):\n",
    "    #true e pred sono [32][245]\n",
    "    \n",
    "    #tensorflow.print(\"tensors:\", y_pred)\n",
    "    #tensorflow.print(\"batch_size:\", tensorflow.shape(y_pred)[0])\n",
    "    \n",
    "    #y_pred = tensorflow.reshape(y_pred, [tensorflow.shape(y_pred)[0], 7, 7, 5])\n",
    "    #y_true = tensorflow.reshape(y_true, [tensorflow.shape(y_pred)[0], 7, 7, 5])\n",
    "\n",
    "\n",
    "    b_p_pred = y_pred[0]\n",
    "    b_x_pred = y_pred[1]\n",
    "    b_y_pred = y_pred[2]\n",
    "    b_w_pred = y_pred[3]\n",
    "    b_h_pred = y_pred[4]\n",
    "\n",
    "\n",
    "    b_p = y_true[0]\n",
    "    b_x = y_true[1]\n",
    "    b_y = y_true[2]\n",
    "    b_w = y_true[3]\n",
    "    b_h = y_true[4]\n",
    "\n",
    "    #print(b_xy_pred.get_shape(),b_xy.get_shape())\n",
    "    #print(b_wh_pred.get_shape(),b_wh.get_shape())\n",
    "    #indicator_coord = K.expand_dims(y_true[ 3], axis=-1) * 1.0\n",
    "    loss_p =K.sum(K.square(b_p - b_p_pred), axis=-1)\n",
    "    loss_xy = K.sum(b_p * (K.square(b_x - b_x_pred) + K.square(b_y - b_y_pred)), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "    \n",
    "    b_w = K.pow(b_w, 0.5)\n",
    "    b_h = K.pow(b_h, 0.5)\n",
    "    b_w_pred = K.pow(b_w_pred, 0.5)\n",
    "    b_h_pred = K.pow(b_h_pred, 0.5)\n",
    "    \n",
    "    loss_wh = K.sum(\n",
    "        b_p * \n",
    "        (\n",
    "            (K.square(b_w - b_w_pred)) + \n",
    "            (K.square(b_h - b_h_pred))\n",
    "        ), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "\n",
    "    #tensorflow.print(\"loss_p:\", loss_p)\n",
    "    #tensorflow.print(\"loss_xy:\", loss_xy)\n",
    "    #tensorflow.print(\"loss_wh:\", loss_wh)\n",
    "\n",
    "    #print(K.cast(loss_p, dtype=\"float32\"))\n",
    "    #print(K.cast(loss_xy, dtype=\"float32\"))\n",
    "    #print(loss_wh)\n",
    "    #tensorflow.print(\"Loss:\", ( K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\") )/3)\n",
    "    return (K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\"))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pandas.read_csv(\"/data01/ML/dataset/FACE_CLASSIFIER/train2.csv\")\n",
    "valid_df = pandas.read_csv(\"/data01/ML/dataset/FACE_CLASSIFIER/val2.csv\")\n",
    "test_df = pandas.read_csv(\"/data01/ML/dataset/FACE_CLASSIFIER/test2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_paths(path_string):\n",
    "    temp = path_string.replace(\"\\\\\", \"/\")  \n",
    "    return \"/data01/ML/\" + temp.split(\"/\",1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_path\"] = train_df[\"image_path\"].apply(convert_paths)\n",
    "valid_df[\"image_path\"] = valid_df[\"image_path\"].apply(convert_paths)\n",
    "test_df[\"image_path\"] = test_df[\"image_path\"].apply(convert_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data01/ML/dataset/FACE_CLASSIFIER/256_ObjectCategories/001.ak47/001_0001.jpg\n"
     ]
    }
   ],
   "source": [
    "print(train_df.iloc[0][\"image_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>p</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data01/ML/dataset/FACE_CLASSIFIER/256_ObjectC...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data01/ML/dataset/FACE_CLASSIFIER/256_ObjectC...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data01/ML/dataset/FACE_CLASSIFIER/256_ObjectC...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  p  x  y  w  h\n",
       "0  /data01/ML/dataset/FACE_CLASSIFIER/256_ObjectC...  0  0  0  0  0\n",
       "1  /data01/ML/dataset/FACE_CLASSIFIER/256_ObjectC...  0  0  0  0  0\n",
       "2  /data01/ML/dataset/FACE_CLASSIFIER/256_ObjectC...  0  0  0  0  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48859 validated image filenames.\n",
      "Found 5430 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "    #preprocessing_function = custom_preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=None,\n",
    "        x_col=\"image_path\",\n",
    "        y_col=[\"p\",\"x\",\"y\",\"w\",\"h\"],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=None,\n",
    "        x_col=\"image_path\",\n",
    "        y_col=[\"p\",\"x\",\"y\",\"w\",\"h\"],\n",
    "        class_mode=\"raw\",\n",
    "        color_mode = 'grayscale',\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.samples/train_generator.batch_size\n",
    "step_size_valid = valid_generator.samples/valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lorenzo.stacchio/Tesi/master_degree_repo/venv/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(IMG_SIZE,IMG_SIZE,1))\n",
    "darknetv1 = (Conv2D(64,3, strides=(1,1), padding = \"same\"))(inp)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (MaxPooling2D(pool_size=(2, 2)))(darknetv1)\n",
    "darknetv1 = (Conv2D(192,3, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (MaxPooling2D(pool_size=(2, 2)))(darknetv1)\n",
    "\n",
    "darknetv1 = (Conv2D(128,1, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(256,3, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(256,1, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(512,3, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (MaxPooling2D(pool_size=(2, 2)))(darknetv1)\n",
    "\n",
    "darknetv1 = (Conv2D(256,1, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(512,3, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(256,1, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(512,3, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(256,1, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(512,3, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(256,1, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(512,3, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(512,1, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "\n",
    "darknetv1 = (Conv2D(1024,3, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (MaxPooling2D(pool_size=(2, 2)))(darknetv1)\n",
    "\n",
    "darknetv1 = (Conv2D(512,1, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(1024,3, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(512,1, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "darknetv1 = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "darknetv1 = (Conv2D(1024,3, strides=(1,1), padding = \"same\"))(darknetv1)\n",
    "darknetv1 = (BatchNormalization())(darknetv1)\n",
    "mid_model = (LeakyReLU(alpha=0.1))(darknetv1)\n",
    "\n",
    "classifier = (GlobalAveragePooling2D())(mid_model)\n",
    "classifier = (Dense(512, activation = \"relu\"))(classifier)\n",
    "classifier = (Dense(512, activation = \"relu\"))(classifier)\n",
    "classifier = (Dense(1, activation = \"sigmoid\"))(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_temp = Model(inputs=[inp], outputs=classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_temp.load_weights(\"face_classifier_BN_GRAYSCALE.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_temp.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Side tuning time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxer = (Conv2D(1024,3, strides=(1,1), padding = \"same\"))(mid_model)\n",
    "bounding_boxer = (BatchNormalization())(bounding_boxer)\n",
    "bounding_boxer = (LeakyReLU(alpha=0.1))(bounding_boxer)\n",
    "bounding_boxer = (Conv2D(1024,3, strides=(1,1), padding = \"same\"))(bounding_boxer)\n",
    "bounding_boxer = (BatchNormalization())(bounding_boxer)\n",
    "bounding_boxer = (LeakyReLU(alpha=0.1))(bounding_boxer)\n",
    "bounding_boxer = (Conv2D(1024,3, strides=(1,1), padding = \"same\"))(bounding_boxer)\n",
    "bounding_boxer = (BatchNormalization())(bounding_boxer)\n",
    "bounding_boxer = (LeakyReLU(alpha=0.1))(bounding_boxer)\n",
    "\n",
    "bounding_boxer = (Flatten())(bounding_boxer)\n",
    "\n",
    "bounding_boxer = (Dense(4096))(bounding_boxer)\n",
    "bounding_boxer = (LeakyReLU(alpha=0.1))(bounding_boxer)\n",
    "bounding_boxer = (Dense(2048))(bounding_boxer)\n",
    "bounding_boxer = (LeakyReLU(alpha=0.1))(bounding_boxer)\n",
    "bounding_boxer = (Dense(4, activation = \"relu\"))(bounding_boxer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Concatenate()([classifier, bounding_boxer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[inp], outputs=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 224, 224, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 64) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 112, 112, 192 110784      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 192 768         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 112, 112, 192 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 192)  0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 128)  24704       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 56, 56, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 256)  295168      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 56, 56, 256)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 256)  65792       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 56, 56, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 512)  1180160     leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 56, 56, 512)  2048        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 56, 56, 512)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 512)  0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 256)  131328      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 28, 28, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 512)  1180160     leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 28, 28, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 28, 28, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 256)  131328      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28, 28, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 28, 28, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 28, 28, 512)  1180160     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 28, 28, 512)  2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 28, 28, 512)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 256)  131328      leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 28, 28, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 512)  1180160     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 512)  2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 512)  2048        batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 28, 28, 512)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 256)  131328      leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 28, 28, 256)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 512)  1180160     leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 28, 28, 512)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 512)  262656      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 28, 28, 512)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 1024) 4719616     leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 1024) 4096        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 28, 28, 1024) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 1024) 0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 14, 14, 512)  524800      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 14, 14, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 14, 14, 512)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 14, 14, 1024) 4719616     leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 14, 14, 1024) 4096        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 14, 14, 1024) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 14, 14, 512)  524800      leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 14, 14, 512)  2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 14, 14, 512)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 14, 14, 1024) 4719616     leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 14, 14, 1024) 4096        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 14, 14, 1024) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 14, 14, 1024) 9438208     leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 14, 14, 1024) 4096        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 14, 14, 1024) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 14, 14, 1024) 9438208     leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 14, 14, 1024) 4096        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 14, 14, 1024) 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 14, 14, 1024) 9438208     leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 14, 14, 1024) 4096        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 14, 14, 1024) 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 200704)       0           leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4096)         822087680   flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1024)         0           leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 4096)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2048)         8390656     leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 2048)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            513         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            8196        leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5)            0           dense_3[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 882,034,117\n",
      "Trainable params: 858,807,300\n",
      "Non-trainable params: 23,226,817\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multi_gpu_model(model,gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr = 1e-4), loss=yolf_loss, metrics=[yolf_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "darknetv1.evaluate_generator(valid_generator, steps=step_size_valid, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lorenzo.stacchio/Tesi/master_degree_repo/venv/lib64/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/lorenzo.stacchio/Tesi/master_degree_repo/venv/lib64/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      " 30/381 [=>............................] - ETA: 16:42 - loss: 979641.0765 - yolf_loss: 979641.1250  "
     ]
    }
   ],
   "source": [
    "#earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "mcp_save = ModelCheckpoint('/data01/ML/standford_darknet.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='min')\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, epochs=20, steps_per_epoch=step_size_train, validation_data=valid_generator, validation_steps=step_size_valid, verbose=1, callbacks=[mcp_save, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training accuracy')\n",
    "plt.plot(val_acc, label='Validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknetv2 = Sequential()\n",
    "darknetv2.add(InputLayer(input_shape=(IMG_SIZE,IMG_SIZE,3)))\n",
    "darknetv2.add(Conv2D(64,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "darknetv2.add(Conv2D(192,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "darknetv2.add(Conv2D(128,1, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(256,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(256,1, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(512,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "darknetv2.add(Conv2D(256,1, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(512,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(256,1, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(512,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(256,1, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(512,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(256,1, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(512,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(512,1, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(1024,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "darknetv2.add(Conv2D(512,1, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(1024,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(512,1, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(1024,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(1024,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(1024,3, strides=(2,2), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(1024,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(1024,3, strides=(1,1), padding = \"same\"))\n",
    "darknetv2.add(BatchNormalization())\n",
    "darknetv2.add(LeakyReLU(alpha=0.1))\n",
    "darknetv2.add(Conv2D(5,1, strides=(1,1), padding = \"same\", activation=\"relu\"))\n",
    "darknetv2.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknetv2.load_weights(\"darknet_ev.h5\") \n",
    "darknetv2.compile(optimizer=Adam(lr = 1e-4), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=validation_set,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=train_df.columns[1:],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)\n",
    "STEP_SIZE_TEST = test_generator.n / test_generator.batch_size \n",
    "\n",
    "\n",
    "#CHANGE PARALLEL MODEL\n",
    "pred=darknetv2.predict_generator(test_generator,  steps=STEP_SIZE_TEST,  verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred[0].reshape(49,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_generator.labels[0].reshape(49,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "max_row = -1\n",
    "list_max = []\n",
    "filename= \"\"\n",
    "for el in zip(pred,test_generator.labels,test_generator.filenames):\n",
    "    count = count +1\n",
    "    for row in el[1].reshape(49,5):\n",
    "        if row[1] > max_row:\n",
    "            max_row =  row[1]\n",
    "            list_max = []\n",
    "            list_max.append(row)\n",
    "            filename = el[2]\n",
    "    try:\n",
    "        list_max = [item for sublist in list_max for item in sublist]\n",
    "        img = Image.open(validation_set+\"\\\\\"+filename)\n",
    "        img1 = ImageDraw.Draw(img)\n",
    "        x1,y1 = (list_max[1]-(list_max[3]/2)),(list_max[2]-(list_max[4]/2))\n",
    "        x4,y4= (list_max[1]+(list_max[3]/2)),(list_max[2]+(list_max[4]/2))\n",
    "        img1.rectangle([(x1,y1),(x4,y4)], outline =\"red\") \n",
    "        img.save(\"./dataset/NUOVO/results/output\"+ str(count) + \".jpg\")\n",
    "        #img.show() \n",
    "    except:\n",
    "        pass\n",
    "    if count == 1000:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
