{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, InputLayer, Flatten, BatchNormalization, Reshape, Lambda\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from IPython.display import Image \n",
    "\n",
    "import keras_metrics\n",
    "import pandas\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arr1 = np.random.randint(245*3, size=(3,7,7,5))\n",
    "arr2 = np.random.randint(245*3, size=(3,7,7,5))\n",
    "\n",
    "arr3 = np.random.randint(245*3, size=(245*3))\n",
    "\n",
    "\n",
    "#y_pred = np.reshape(y_pred, (BATCH_SIZE, 7,7,5))\n",
    "batch_size = tensorflow.shape(arr3).numpy()[0]/245\n",
    "print(tensorflow.shape(arr3).numpy())\n",
    "print(batch_size)\n",
    "#y_pred = tensorflow.reshape(y_pred, [batch_size, 7, 7, 5])\n",
    "#y_true = np.reshape(y_true, (BATCH_SIZE, 7,7,5))\n",
    "#y_true = tensorflow.reshape(y_true, [batch_size, 7, 7, 5])\n",
    "\n",
    "\n",
    "b_p_pred = arr2[..., 0]\n",
    "b_x_pred = arr2[..., 1]\n",
    "b_y_pred = arr2[..., 2]\n",
    "b_w_pred = arr2[..., 3]\n",
    "b_h_pred = arr2[..., 4]\n",
    "\n",
    "\n",
    "b_p = arr1[..., 0]\n",
    "b_x = arr1[..., 1]\n",
    "b_y = arr1[..., 2]\n",
    "b_w = arr1[..., 3]\n",
    "b_h = arr1[..., 4]\n",
    "\n",
    "#print(b_xy_pred.get_shape(),b_xy.get_shape())\n",
    "#print(b_wh_pred.get_shape(),b_wh.get_shape())\n",
    "#indicator_coord = K.expand_dims(y_true[..., 3], axis=-1) * 1.0\n",
    "loss_p = K.sum(K.square(b_p - b_p_pred), axis=-1)\n",
    "loss_xy = K.sum(b_p * (K.square(b_x - b_x_pred) + K.square(b_y - b_y_pred)), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "loss_wh = K.sum(\n",
    "    b_p * \n",
    "    (\n",
    "        (K.square(K.sqrt(K.cast(b_w, dtype=\"float32\")) - K.sqrt(K.cast(b_w_pred, dtype=\"float32\")))) + \n",
    "        (K.square(K.sqrt(K.cast(b_h, dtype=\"float32\")) - K.sqrt(K.cast(b_h_pred, dtype=\"float32\"))))\n",
    "    ), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "\n",
    "K.print_tensor(K.sqrt( K.cast(b_w, dtype=\"float32\") ) ,message='b_w: = ')\n",
    "\n",
    "K.print_tensor(loss_p, message=\"loss_p: \")\n",
    "K.print_tensor(loss_xy, message=\"loss_xy: \")\n",
    "K.print_tensor(loss_wh, message=\"loss_wh: \")\n",
    "\n",
    "#print(K.cast(loss_p, dtype=\"float32\"))\n",
    "#print(K.cast(loss_xy, dtype=\"float32\"))\n",
    "#print(loss_wh)\n",
    "K.print_tensor(( K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\") )/3, message=\"loss: \")\n",
    "print (( K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\") )/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolf_loss(y_true, y_pred):\n",
    "    #true e pred sono [32][245]\n",
    "    \n",
    "    #tensorflow.print(\"tensors:\", y_pred)\n",
    "    #tensorflow.print(\"batch_size:\", tensorflow.shape(y_pred)[0])\n",
    "    \n",
    "    y_pred = tensorflow.reshape(y_pred, [tensorflow.shape(y_pred)[0], 7, 7, 5])\n",
    "    y_true = tensorflow.reshape(y_true, [tensorflow.shape(y_pred)[0], 7, 7, 5])\n",
    "\n",
    "\n",
    "    b_p_pred = y_pred[..., 0]\n",
    "    b_x_pred = y_pred[..., 1]\n",
    "    b_y_pred = y_pred[..., 2]\n",
    "    b_w_pred = y_pred[..., 3]\n",
    "    b_h_pred = y_pred[..., 4]\n",
    "\n",
    "\n",
    "    b_p = y_true[..., 0]\n",
    "    b_x = y_true[..., 1]\n",
    "    b_y = y_true[..., 2]\n",
    "    b_w = y_true[..., 3]\n",
    "    b_h = y_true[..., 4]\n",
    "\n",
    "    #print(b_xy_pred.get_shape(),b_xy.get_shape())\n",
    "    #print(b_wh_pred.get_shape(),b_wh.get_shape())\n",
    "    #indicator_coord = K.expand_dims(y_true[..., 3], axis=-1) * 1.0\n",
    "    loss_p = K.sum(K.square(b_p - b_p_pred), axis=-1)\n",
    "    loss_xy = K.sum(b_p * (K.square(b_x - b_x_pred) + K.square(b_y - b_y_pred)), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "    \n",
    "    b_w = K.pow(b_w, 0.5)\n",
    "    b_h = K.pow(b_h, 0.5)\n",
    "    b_w_pred = K.pow(b_w_pred, 0.5)\n",
    "    b_h_pred = K.pow(b_h_pred, 0.5)\n",
    "    \n",
    "    loss_wh = K.sum(\n",
    "        b_p * \n",
    "        (\n",
    "            (K.square(b_w - b_w_pred)) + \n",
    "            (K.square(b_h - b_h_pred))\n",
    "        ), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "\n",
    "    #tensorflow.print(\"loss_p:\", loss_p)\n",
    "    #tensorflow.print(\"loss_xy:\", loss_xy)\n",
    "    #tensorflow.print(\"loss_wh:\", loss_wh)\n",
    "\n",
    "    #print(K.cast(loss_p, dtype=\"float32\"))\n",
    "    #print(K.cast(loss_xy, dtype=\"float32\"))\n",
    "    #print(loss_wh)\n",
    "    #tensorflow.print(\"Loss:\", ( K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\") )/3)\n",
    "    return (K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\"))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = \"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/train/\"\n",
    "validation_set = \"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/val/\"\n",
    "test_set = \"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pandas.read_csv(\"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/train/output_segmentation.csv\")\n",
    "valid_df = pandas.read_csv(\"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/val/output_segmentation.csv\")\n",
    "test_df = pandas.read_csv(\"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/test/output_segmentation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df['label'] = train_df['label'].apply(lambda x: ast.literal_eval(x))\n",
    "valid_df['label'] = valid_df['label'].apply(lambda x: ast.literal_eval(x))\n",
    "test_df['label'] = test_df['label'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMG_SIZE = 224\n",
    "BLOCKS_NUM = 19\n",
    "BLOCK_SIZE = IMG_SIZE / BLOCKS_NUM\n",
    "\n",
    "path_train_image = \".\\\\dataset\\\\NUOVO\\\\train\"\n",
    "count = 0 \n",
    "for index,row in train_df.iterrows(): \n",
    "    im = Image.open(\".\\\\dataset\\\\NUOVO\\\\train\\\\\" + row[\"image_id\"], 'r')\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    for i in range(BLOCKS_NUM):\n",
    "        for j in range(BLOCKS_NUM):\n",
    "\n",
    "            #print(ast.literal_eval(row[\"label\"])[(i*19)+j])\n",
    "            \n",
    "            if(row[\"label\"][(i*19)+j][0] == 1):\n",
    "                draw.rectangle(((i * BLOCK_SIZE, j * BLOCK_SIZE), (i * BLOCK_SIZE + BLOCK_SIZE, j * BLOCK_SIZE + BLOCK_SIZE)), outline=\"Green\")\n",
    "            else:\n",
    "                draw.rectangle(((i * BLOCK_SIZE, j * BLOCK_SIZE), (i * BLOCK_SIZE + BLOCK_SIZE, j * BLOCK_SIZE + BLOCK_SIZE)), outline=\"Black\")\n",
    "    count += 1\n",
    "    im.show()\n",
    "    if(count == 1):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df['label'] = train_df['label'].apply(lambda x: np.asarray(x).flatten())\n",
    "valid_df['label'] = valid_df['label'].apply(lambda x: np.asarray(x).flatten())\n",
    "test_df['label'] = test_df['label'].apply(lambda x: np.asarray(x).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for el in range(valid_df.label[0].shape[0]):\n",
    "    valid_df[str(el)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(valid_df.label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count = 0\n",
    "for index, row in valid_df.iterrows():\n",
    "    count = count +1\n",
    "    if count%1000==0:\n",
    "        print(\"Done\", count, \"rows\")\n",
    "    for el in range(valid_df.label[0].shape[0]):\n",
    "        valid_df[str(el)][index] = valid_df['label'][index][el]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for el in range(valid_df.label[0].shape[0]):\n",
    "    print(valid_df[str(el)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=train_set,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=train_df.columns[1:],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=validation_set,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=valid_df.columns[1:],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_generator.reset()\n",
    "\n",
    "for el in train_generator:\n",
    "    images = el[0]\n",
    "    label = el[1]\n",
    "    for l in label:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.samples/train_generator.batch_size\n",
    "step_size_valid = valid_generator.samples/valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "true_boxes  = Input(shape=(1, 1, 1, 1, 1))\n",
    "#input_image = Input(shape=(224, 224, 3))\n",
    "input_image = InputLayer(input_shape=(224,224,3))\n",
    "\n",
    "model = Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(input_image)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=64, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=128, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "          \n",
    "model = Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "\n",
    "model = Conv2D(filters=5, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "\n",
    "model = Reshape((7, 7, 5))(model)\n",
    "\n",
    "#output = Lambda(lambda args: args[0])([model, true_boxes])\n",
    "\n",
    "model = Sequential(input_image, output)\n",
    "\n",
    "\n",
    "#model = Conv2D(filters=4, kernel_size=(1,1)))\n",
    "#model = GlobalAveragePooling2D())\n",
    "#model = BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f62e662a354b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224,224,3)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "          \n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=5, kernel_size=(1,1), activation=\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(245, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#output = Lambda(lambda args: args[0])([model, true_boxes])\n",
    "\n",
    "#model = Sequential(input_image, output)\n",
    "\n",
    "#model.add(Conv2D(filters=4, kernel_size=(1,1)))\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "#model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = multi_gpu_model(model, gpus=2) #parallelize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr = 1e-4), loss=yolf_loss, metrics=[yolf_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(valid_generator, steps=step_size_valid, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min')\n",
    "mcp_save = ModelCheckpoint('yolf.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min')\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, epochs=135, steps_per_epoch=step_size_train, validation_data=valid_generator, validation_steps=step_size_valid, verbose=1, callbacks=[mcp_save, earlyStopping, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training accuracy')\n",
    "plt.plot(val_acc, label='Validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim([min(plt.ylim()),500])\n",
    "plt.title('Training and Validation accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,20000])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                    directory=test_set,\n",
    "                                    x_col=\"image_id\",\n",
    "                                    y_col=[\"x_1\",\"y_1\",\"width\",\"height\"],\n",
    "                                    class_mode=\"raw\",\n",
    "                                    shuffle=True,\n",
    "                                    target_size=(224, 224),\n",
    "                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n / test_generator.batch_size \n",
    "\n",
    "\n",
    "#CHANGE PARALLEL MODEL\n",
    "pred=model.predict_generator(test_generator,  steps=STEP_SIZE_TEST,  verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange output of pred\n",
    "min_x, min_y = 100000,100000\n",
    "max_x, max_y = -1,-1\n",
    "\n",
    "BLOCK_SIZE = 32\n",
    "for predict in pred:\n",
    "    #np arrange qualcosa con 49 x 5\n",
    "    for el in arranged:\n",
    "        if el[0] == 1:\n",
    "            temp_width, temp_height = el[3]*BLOCK_SIZE, el[4]*BLOCK_SIZE,\n",
    "            temp_lt_x, temp_lt_y = el[1]-temp_width/2, el[2]-temp_heigth/2\n",
    "            temp_rb_x, temp_rb_y = el[1]-temp_width/2, el[2]-temp_heigth/2\n",
    "            if temp_lt_x<=min_x and temp_lt_y<=min_y:\n",
    "                min_x, min_y= temp_lt_x,temp_lt_y\n",
    "            else if temp_rb_x>=max_x and temp_rb_y>=max_y:\n",
    "                max_x, max_y= temp_lt_x,temp_lt_y\n",
    "\n",
    "print(min_x, min_y,max_x, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import  Image, ImageDraw\n",
    "\n",
    "count = 0\n",
    "\n",
    "for gen_image in test_generator:\n",
    "    img = Image.fromarray(np.uint8((gen_image[0][0])*255))\n",
    "    img1 = ImageDraw.Draw(img)\n",
    "    x1,y1 = pred[count][0],pred[count][1]\n",
    "    x4,y4= pred[count][0] + pred[count][2], pred[count][1] + pred[count][3]\n",
    "    img1.rectangle([(x1,y1),(x4,y4)], outline =\"red\") \n",
    "    #img.show() \n",
    "    img.save(\"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/results/output\"+ str(count) + \".jpg\")\n",
    "    #print(gen_image[0][0].shape,pred[count])\n",
    "    count = count + 1\n",
    "    if count == 1000:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
