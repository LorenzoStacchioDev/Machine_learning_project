{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, InputLayer, Flatten, BatchNormalization, Reshape, Lambda\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from IPython.display import Image \n",
    "\n",
    "import keras_metrics\n",
    "import pandas\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def yolf_loss(y_true, y_pred):\n",
    "    b_p_pred = y_pred[..., :0]\n",
    "    b_xy_pred = y_pred[..., 1:3]\n",
    "    b_wh_pred = y_pred[..., 3:5]\n",
    "    \n",
    "    b_p = y_true[..., 0]\n",
    "    b_xy = y_true[..., 1:3]\n",
    "    b_wh = y_true[..., 3:5]\n",
    "    #print(b_xy_pred.get_shape(),b_xy.get_shape())\n",
    "    #print(b_wh_pred.get_shape(),b_wh.get_shape())\n",
    "    #indicator_coord = K.expand_dims(y_true[..., 3], axis=-1) * 1.0\n",
    "    loss_p = K.sum(K.square(b_p - b_p_pred), axis=-1)\n",
    "    loss_xy = K.sum(b_p * K.square(b_xy - b_xy_pred), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "    loss_wh = K.sum(b_p * K.square(K.sqrt(b_wh) - K.sqrt(b_wh_pred)), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "    return (loss_p + loss_wh + loss_xy)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = \".\\\\dataset\\\\NUOVO\\\\train\\\\\"\n",
    "validation_set = \".\\\\dataset\\\\NUOVO\\\\val\\\\\"\n",
    "test_set = \".\\\\dataset\\\\NUOVO\\\\test\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pandas.read_csv(\".\\\\dataset\\\\NUOVO\\\\train\\\\output_segmentation.csv\")\n",
    "valid_df = pandas.read_csv(\".\\\\dataset\\\\NUOVO\\\\val\\\\output_segmentation.csv\")\n",
    "test_df = pandas.read_csv(\".\\\\dataset\\\\NUOVO\\\\test\\\\output_segmentation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df['label'] = train_df['label'].apply(lambda x: ast.literal_eval(x))\n",
    "valid_df['label'] = valid_df['label'].apply(lambda x: ast.literal_eval(x))\n",
    "test_df['label'] = test_df['label'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMG_SIZE = 224\n",
    "BLOCKS_NUM = 19\n",
    "BLOCK_SIZE = IMG_SIZE / BLOCKS_NUM\n",
    "\n",
    "path_train_image = \".\\\\dataset\\\\NUOVO\\\\train\"\n",
    "count = 0 \n",
    "for index,row in train_df.iterrows(): \n",
    "    im = Image.open(\".\\\\dataset\\\\NUOVO\\\\train\\\\\" + row[\"image_id\"], 'r')\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    for i in range(BLOCKS_NUM):\n",
    "        for j in range(BLOCKS_NUM):\n",
    "\n",
    "            #print(ast.literal_eval(row[\"label\"])[(i*19)+j])\n",
    "            \n",
    "            if(row[\"label\"][(i*19)+j][0] == 1):\n",
    "                draw.rectangle(((i * BLOCK_SIZE, j * BLOCK_SIZE), (i * BLOCK_SIZE + BLOCK_SIZE, j * BLOCK_SIZE + BLOCK_SIZE)), outline=\"Green\")\n",
    "            else:\n",
    "                draw.rectangle(((i * BLOCK_SIZE, j * BLOCK_SIZE), (i * BLOCK_SIZE + BLOCK_SIZE, j * BLOCK_SIZE + BLOCK_SIZE)), outline=\"Black\")\n",
    "    count += 1\n",
    "    im.show()\n",
    "    if(count == 1):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df['label'] = train_df['label'].apply(lambda x: np.asarray(x).flatten())\n",
    "valid_df['label'] = valid_df['label'].apply(lambda x: np.asarray(x).flatten())\n",
    "test_df['label'] = test_df['label'].apply(lambda x: np.asarray(x).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for el in range(valid_df.label[0].shape[0]):\n",
    "    valid_df[str(el)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(valid_df.label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count = 0\n",
    "for index, row in valid_df.iterrows():\n",
    "    count = count +1\n",
    "    if count%1000==0:\n",
    "        print(\"Done\", count, \"rows\")\n",
    "    for el in range(valid_df.label[0].shape[0]):\n",
    "        valid_df[str(el)][index] = valid_df['label'][index][el]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for el in range(valid_df.label[0].shape[0]):\n",
    "    print(valid_df[str(el)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ...\n",
       "       '235', '236', '237', '238', '239', '240', '241', '242', '243', '244'],\n",
       "      dtype='object', length=245)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 164105 validated image filenames.\n",
      "Found 18234 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=train_set,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=train_df.columns[1:],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=validation_set,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=valid_df.columns[1:],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_generator.reset()\n",
    "\n",
    "for el in train_generator:\n",
    "    images = el[0]\n",
    "    label = el[1]\n",
    "    for l in label:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.samples/train_generator.batch_size\n",
    "step_size_valid = valid_generator.samples/valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "true_boxes  = Input(shape=(1, 1, 1, 1, 1))\n",
    "#input_image = Input(shape=(224, 224, 3))\n",
    "input_image = InputLayer(input_shape=(224,224,3))\n",
    "\n",
    "model = Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(input_image)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=64, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=128, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "          \n",
    "model = Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "\n",
    "model = Conv2D(filters=5, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "\n",
    "model = Reshape((7, 7, 5))(model)\n",
    "\n",
    "#output = Lambda(lambda args: args[0])([model, true_boxes])\n",
    "\n",
    "model = Sequential(input_image, output)\n",
    "\n",
    "\n",
    "#model = Conv2D(filters=4, kernel_size=(1,1)))\n",
    "#model = GlobalAveragePooling2D())\n",
    "#model = BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224,224,3)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "          \n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=5, kernel_size=(1,1), activation=\"relu\"))\n",
    "\n",
    "#model.add(Reshape((245, 1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#output = Lambda(lambda args: args[0])([model, true_boxes])\n",
    "\n",
    "#model = Sequential(input_image, output)\n",
    "\n",
    "#model.add(Conv2D(filters=4, kernel_size=(1,1)))\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "#model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 128)       32896     \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 14, 14, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 7, 7, 512)         524800    \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 512)         524800    \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 7, 7, 5)           5125      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 245)               0         \n",
      "=================================================================\n",
      "Total params: 19,819,269\n",
      "Trainable params: 19,817,285\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = multi_gpu_model(model, gpus=2) #parallelize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr = 1e-4), loss=\"mse\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/569 [==============================] - 31s 55ms/step - loss: 1980.6954 - mse: 1980.7390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1981.3460120430925, 1980.739]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(valid_generator, steps=step_size_valid, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5129/5128 [==============================] - 891s 174ms/step - loss: 209.3634 - mse: 209.3724 - val_loss: 151.1521 - val_mse: 151.0975\n",
      "Epoch 2/10\n",
      "5129/5128 [==============================] - 838s 163ms/step - loss: 130.8876 - mse: 130.8973 - val_loss: 123.0750 - val_mse: 123.0214\n",
      "Epoch 3/10\n",
      "5129/5128 [==============================] - 824s 161ms/step - loss: 112.3384 - mse: 112.3301 - val_loss: 122.3660 - val_mse: 122.3201\n",
      "Epoch 4/10\n",
      "5129/5128 [==============================] - 831s 162ms/step - loss: 99.4011 - mse: 99.3963 - val_loss: 123.7437 - val_mse: 123.7186\n",
      "Epoch 5/10\n",
      "5129/5128 [==============================] - 828s 161ms/step - loss: 88.0731 - mse: 88.0815 - val_loss: 106.6786 - val_mse: 106.6540\n",
      "Epoch 6/10\n",
      "5129/5128 [==============================] - 826s 161ms/step - loss: 78.6207 - mse: 78.6049 - val_loss: 108.5776 - val_mse: 108.5595\n",
      "Epoch 7/10\n",
      "5129/5128 [==============================] - 826s 161ms/step - loss: 68.9992 - mse: 69.0038 - val_loss: 106.2708 - val_mse: 106.2239\n",
      "Epoch 8/10\n",
      "5129/5128 [==============================] - 827s 161ms/step - loss: 60.3657 - mse: 60.3737 - val_loss: 110.8219 - val_mse: 110.8106\n",
      "Epoch 9/10\n",
      "5129/5128 [==============================] - 824s 161ms/step - loss: 52.7585 - mse: 52.7530 - val_loss: 111.8396 - val_mse: 111.7598\n",
      "Epoch 10/10\n",
      "5129/5128 [==============================] - 823s 161ms/step - loss: 46.7444 - mse: 46.7506 - val_loss: 113.7464 - val_mse: 113.7180\n"
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min')\n",
    "mcp_save = ModelCheckpoint('yolf.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min')\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, epochs=10, steps_per_epoch=step_size_train, validation_data=valid_generator, validation_steps=step_size_valid, verbose=1, callbacks=[mcp_save, earlyStopping, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [209.37247939356348, 130.89733179491705, 112.329916109771, 99.39633042176366, 88.0813424002176, 78.60487301518678, 69.00396133726902, 60.37362299094757, 52.752996699251625, 46.7506385540084], 'mse': [209.37242, 130.89731, 112.330055, 99.396286, 88.08154, 78.60493, 69.0038, 60.37367, 52.753036, 46.75062], 'val_loss': [151.15205725899676, 123.07500939862409, 122.36595800679491, 123.74365729779362, 106.67858649728015, 108.57758578582593, 106.27078395022156, 110.82191314144957, 111.8396373454633, 113.7464084991358], 'val_mse': [151.0975, 123.02143, 122.320114, 123.71861, 106.65402, 108.55953, 106.223885, 110.8106, 111.75982, 113.71804], 'lr': [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-64c42177a7e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training accuracy')\n",
    "plt.plot(val_acc, label='Validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim([min(plt.ylim()),500])\n",
    "plt.title('Training and Validation accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,20000])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                    directory=test_set,\n",
    "                                    x_col=\"image_id\",\n",
    "                                    y_col=[\"x_1\",\"y_1\",\"width\",\"height\"],\n",
    "                                    class_mode=\"raw\",\n",
    "                                    shuffle=True,\n",
    "                                    target_size=(224, 224),\n",
    "                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n / test_generator.batch_size \n",
    "\n",
    "\n",
    "#CHANGE PARALLEL MODEL\n",
    "pred=model.predict_generator(test_generator,  steps=STEP_SIZE_TEST,  verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import  Image, ImageDraw\n",
    "\n",
    "count = 0\n",
    "\n",
    "for gen_image in test_generator:\n",
    "    img = Image.fromarray(np.uint8((gen_image[0][0])*255))\n",
    "    img1 = ImageDraw.Draw(img)\n",
    "    x1,y1 = pred[count][0],pred[count][1]\n",
    "    x4,y4= pred[count][0] + pred[count][2], pred[count][1] + pred[count][3]\n",
    "    img1.rectangle([(x1,y1),(x4,y4)], outline =\"red\") \n",
    "    #img.show() \n",
    "    img.save(\"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/results/output\"+ str(count) + \".jpg\")\n",
    "    #print(gen_image[0][0].shape,pred[count])\n",
    "    count = count + 1\n",
    "    if count == 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
