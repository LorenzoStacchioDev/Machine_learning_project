{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, InputLayer, Flatten, BatchNormalization, Reshape, Lambda\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from IPython.display import Image \n",
    "\n",
    "import keras_metrics\n",
    "import pandas\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arr1 = np.random.randint(245*3, size=(3,7,7,5))\n",
    "arr2 = np.random.randint(245*3, size=(3,7,7,5))\n",
    "\n",
    "arr3 = np.random.randint(245*3, size=(245*3))\n",
    "\n",
    "\n",
    "#y_pred = np.reshape(y_pred, (BATCH_SIZE, 7,7,5))\n",
    "batch_size = tensorflow.shape(arr3).numpy()[0]/245\n",
    "print(tensorflow.shape(arr3).numpy())\n",
    "print(batch_size)\n",
    "#y_pred = tensorflow.reshape(y_pred, [batch_size, 7, 7, 5])\n",
    "#y_true = np.reshape(y_true, (BATCH_SIZE, 7,7,5))\n",
    "#y_true = tensorflow.reshape(y_true, [batch_size, 7, 7, 5])\n",
    "\n",
    "\n",
    "b_p_pred = arr2[..., 0]\n",
    "b_x_pred = arr2[..., 1]\n",
    "b_y_pred = arr2[..., 2]\n",
    "b_w_pred = arr2[..., 3]\n",
    "b_h_pred = arr2[..., 4]\n",
    "\n",
    "\n",
    "b_p = arr1[..., 0]\n",
    "b_x = arr1[..., 1]\n",
    "b_y = arr1[..., 2]\n",
    "b_w = arr1[..., 3]\n",
    "b_h = arr1[..., 4]\n",
    "\n",
    "#print(b_xy_pred.get_shape(),b_xy.get_shape())\n",
    "#print(b_wh_pred.get_shape(),b_wh.get_shape())\n",
    "#indicator_coord = K.expand_dims(y_true[..., 3], axis=-1) * 1.0\n",
    "loss_p = K.sum(K.square(b_p - b_p_pred), axis=-1)\n",
    "loss_xy = K.sum(b_p * (K.square(b_x - b_x_pred) + K.square(b_y - b_y_pred)), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "loss_wh = K.sum(\n",
    "    b_p * \n",
    "    (\n",
    "        (K.square(K.sqrt(K.cast(b_w, dtype=\"float32\")) - K.sqrt(K.cast(b_w_pred, dtype=\"float32\")))) + \n",
    "        (K.square(K.sqrt(K.cast(b_h, dtype=\"float32\")) - K.sqrt(K.cast(b_h_pred, dtype=\"float32\"))))\n",
    "    ), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "\n",
    "K.print_tensor(K.sqrt( K.cast(b_w, dtype=\"float32\") ) ,message='b_w: = ')\n",
    "\n",
    "K.print_tensor(loss_p, message=\"loss_p: \")\n",
    "K.print_tensor(loss_xy, message=\"loss_xy: \")\n",
    "K.print_tensor(loss_wh, message=\"loss_wh: \")\n",
    "\n",
    "#print(K.cast(loss_p, dtype=\"float32\"))\n",
    "#print(K.cast(loss_xy, dtype=\"float32\"))\n",
    "#print(loss_wh)\n",
    "K.print_tensor(( K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\") )/3, message=\"loss: \")\n",
    "print (( K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\") )/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolf_loss(y_true, y_pred):\n",
    "    #true e pred sono [32][245]\n",
    "    \n",
    "    #tensorflow.print(\"tensors:\", y_pred)\n",
    "    #tensorflow.print(\"batch_size:\", tensorflow.shape(y_pred)[0])\n",
    "    \n",
    "    y_pred = tensorflow.reshape(y_pred, [tensorflow.shape(y_pred)[0], 7, 7, 5])\n",
    "    y_true = tensorflow.reshape(y_true, [tensorflow.shape(y_pred)[0], 7, 7, 5])\n",
    "\n",
    "\n",
    "    b_p_pred = y_pred[..., 0]\n",
    "    b_x_pred = y_pred[..., 1]\n",
    "    b_y_pred = y_pred[..., 2]\n",
    "    b_w_pred = y_pred[..., 3]\n",
    "    b_h_pred = y_pred[..., 4]\n",
    "\n",
    "\n",
    "    b_p = y_true[..., 0]\n",
    "    b_x = y_true[..., 1]\n",
    "    b_y = y_true[..., 2]\n",
    "    b_w = y_true[..., 3]\n",
    "    b_h = y_true[..., 4]\n",
    "\n",
    "    #print(b_xy_pred.get_shape(),b_xy.get_shape())\n",
    "    #print(b_wh_pred.get_shape(),b_wh.get_shape())\n",
    "    #indicator_coord = K.expand_dims(y_true[..., 3], axis=-1) * 1.0\n",
    "    loss_p = K.sum(K.square(b_p - b_p_pred), axis=-1)\n",
    "    loss_xy = 5*K.sum(b_p * (K.square(b_x - b_x_pred) + K.square(b_y - b_y_pred)), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "    \n",
    "    b_w = K.pow(b_w, 0.5)\n",
    "    b_h = K.pow(b_h, 0.5)\n",
    "    b_w_pred = K.pow(b_w_pred, 0.5)\n",
    "    b_h_pred = K.pow(b_h_pred, 0.5)\n",
    "    \n",
    "    loss_wh = 5*K.sum(\n",
    "        b_p * \n",
    "        (\n",
    "            (K.square(b_w - b_w_pred)) + \n",
    "            (K.square(b_h - b_h_pred))\n",
    "        ), axis=-1)# * indicator_coord)#, axis=[1,2,3,4])\n",
    "\n",
    "    #tensorflow.print(\"loss_p:\", loss_p)\n",
    "    #tensorflow.print(\"loss_xy:\", loss_xy)\n",
    "    #tensorflow.print(\"loss_wh:\", loss_wh)\n",
    "\n",
    "    #print(K.cast(loss_p, dtype=\"float32\"))\n",
    "    #print(K.cast(loss_xy, dtype=\"float32\"))\n",
    "    #print(loss_wh)\n",
    "    #tensorflow.print(\"Loss:\", ( K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\") )/3)\n",
    "    return ( K.cast(loss_p, dtype=\"float32\") + loss_wh +  K.cast(loss_xy, dtype=\"float32\") )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = \".\\\\dataset\\\\NUOVO\\\\train\\\\\"\n",
    "validation_set = \".\\\\dataset\\\\NUOVO\\\\val\\\\\"\n",
    "test_set = \".\\\\dataset\\\\NUOVO\\\\test\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pandas.read_csv(\".\\\\dataset\\\\NUOVO\\\\train\\\\output_segmentation.csv\")\n",
    "valid_df = pandas.read_csv(\".\\\\dataset\\\\NUOVO\\\\val\\\\output_segmentation.csv\")\n",
    "test_df = pandas.read_csv(\".\\\\dataset\\\\NUOVO\\\\test\\\\output_segmentation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df['label'] = train_df['label'].apply(lambda x: ast.literal_eval(x))\n",
    "valid_df['label'] = valid_df['label'].apply(lambda x: ast.literal_eval(x))\n",
    "test_df['label'] = test_df['label'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMG_SIZE = 224\n",
    "BLOCKS_NUM = 19\n",
    "BLOCK_SIZE = IMG_SIZE / BLOCKS_NUM\n",
    "\n",
    "path_train_image = \".\\\\dataset\\\\NUOVO\\\\train\"\n",
    "count = 0 \n",
    "for index,row in train_df.iterrows(): \n",
    "    im = Image.open(\".\\\\dataset\\\\NUOVO\\\\train\\\\\" + row[\"image_id\"], 'r')\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    for i in range(BLOCKS_NUM):\n",
    "        for j in range(BLOCKS_NUM):\n",
    "\n",
    "            #print(ast.literal_eval(row[\"label\"])[(i*19)+j])\n",
    "            \n",
    "            if(row[\"label\"][(i*19)+j][0] == 1):\n",
    "                draw.rectangle(((i * BLOCK_SIZE, j * BLOCK_SIZE), (i * BLOCK_SIZE + BLOCK_SIZE, j * BLOCK_SIZE + BLOCK_SIZE)), outline=\"Green\")\n",
    "            else:\n",
    "                draw.rectangle(((i * BLOCK_SIZE, j * BLOCK_SIZE), (i * BLOCK_SIZE + BLOCK_SIZE, j * BLOCK_SIZE + BLOCK_SIZE)), outline=\"Black\")\n",
    "    count += 1\n",
    "    im.show()\n",
    "    if(count == 1):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df['label'] = train_df['label'].apply(lambda x: np.asarray(x).flatten())\n",
    "valid_df['label'] = valid_df['label'].apply(lambda x: np.asarray(x).flatten())\n",
    "test_df['label'] = test_df['label'].apply(lambda x: np.asarray(x).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for el in range(valid_df.label[0].shape[0]):\n",
    "    valid_df[str(el)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(valid_df.label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count = 0\n",
    "for index, row in valid_df.iterrows():\n",
    "    count = count +1\n",
    "    if count%1000==0:\n",
    "        print(\"Done\", count, \"rows\")\n",
    "    for el in range(valid_df.label[0].shape[0]):\n",
    "        valid_df[str(el)][index] = valid_df['label'][index][el]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for el in range(valid_df.label[0].shape[0]):\n",
    "    print(valid_df[str(el)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ...\n",
       "       '235', '236', '237', '238', '239', '240', '241', '242', '243', '244'],\n",
       "      dtype='object', length=245)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 164105 validated image filenames.\n",
      "Found 18234 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=train_set,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=train_df.columns[1:],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=validation_set,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=valid_df.columns[1:],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_generator.reset()\n",
    "\n",
    "for el in train_generator:\n",
    "    images = el[0]\n",
    "    label = el[1]\n",
    "    for l in label:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.samples/train_generator.batch_size\n",
    "step_size_valid = valid_generator.samples/valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "true_boxes  = Input(shape=(1, 1, 1, 1, 1))\n",
    "#input_image = Input(shape=(224, 224, 3))\n",
    "input_image = InputLayer(input_shape=(224,224,3))\n",
    "\n",
    "model = Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(input_image)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=64, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=128, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "\n",
    "model = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPooling2D(pool_size=(2,2), strides=2)(model)\n",
    "          \n",
    "model = Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "model = Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "model = Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(model)\n",
    "\n",
    "model = Conv2D(filters=5, kernel_size=(1,1), activation=\"relu\")(model)\n",
    "\n",
    "model = Reshape((7, 7, 5))(model)\n",
    "\n",
    "#output = Lambda(lambda args: args[0])([model, true_boxes])\n",
    "\n",
    "model = Sequential(input_image, output)\n",
    "\n",
    "\n",
    "#model = Conv2D(filters=4, kernel_size=(1,1)))\n",
    "#model = GlobalAveragePooling2D())\n",
    "#model = BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224,224,3)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "          \n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=5, kernel_size=(1,1), activation=\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(245, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#output = Lambda(lambda args: args[0])([model, true_boxes])\n",
    "\n",
    "#model = Sequential(input_image, output)\n",
    "\n",
    "#model.add(Conv2D(filters=4, kernel_size=(1,1)))\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "#model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 128)       32896     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 512)         524800    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 7, 512)         524800    \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 7, 7, 5)           5125      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 245)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              1007616   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 245)               1003765   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 245)               0         \n",
      "=================================================================\n",
      "Total params: 21,830,650\n",
      "Trainable params: 21,828,666\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = multi_gpu_model(model, gpus=2) #parallelize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr = 1e-3), loss=yolf_loss, metrics=[yolf_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/569 [==============================] - 35s 61ms/step - loss: 115544.3372 - yolf_loss: 115540.1719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[115582.29111824065, 115540.17]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(valid_generator, steps=step_size_valid, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 584/5128 [==>...........................] - ETA: 11:57 - loss: 115778.7685 - yolf_loss: 115778.8281"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-423a305d3d9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreduce_lr_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep_size_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep_size_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmcp_save\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearlyStopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_lr_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m               training=training))\n\u001b[0m\u001b[0;32m    253\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    254\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m     \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_training_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36m_get_training_value\u001b[1;34m(self, training)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_trainable_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lorenzo\\desktop\\università\\machine_learning_project\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mlogical_and\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   5858\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   5859\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5860\u001b[1;33m         \"LogicalAnd\", name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[0;32m   5861\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5862\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min')\n",
    "mcp_save = ModelCheckpoint('yolf.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min')\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, epochs=3, steps_per_epoch=step_size_train, validation_data=valid_generator, validation_steps=step_size_valid, verbose=1, callbacks=[mcp_save, earlyStopping, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training accuracy')\n",
    "plt.plot(val_acc, label='Validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim([min(plt.ylim()),500])\n",
    "plt.title('Training and Validation accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,20000])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                    directory=test_set,\n",
    "                                    x_col=\"image_id\",\n",
    "                                    y_col=[\"x_1\",\"y_1\",\"width\",\"height\"],\n",
    "                                    class_mode=\"raw\",\n",
    "                                    shuffle=True,\n",
    "                                    target_size=(224, 224),\n",
    "                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n / test_generator.batch_size \n",
    "\n",
    "\n",
    "#CHANGE PARALLEL MODEL\n",
    "pred=model.predict_generator(test_generator,  steps=STEP_SIZE_TEST,  verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange output of pred\n",
    "min_x, min_y = 100000,100000\n",
    "max_x, max_y = -1,-1\n",
    "\n",
    "BLOCK_SIZE = 32\n",
    "for predict in pred:\n",
    "    #np arrange qualcosa con 49 x 5\n",
    "    for el in arranged:\n",
    "        if el[0] == 1:\n",
    "            temp_width, temp_height = el[3]*BLOCK_SIZE, el[4]*BLOCK_SIZE,\n",
    "            temp_lt_x, temp_lt_y = el[1]-temp_width/2, el[2]-temp_heigth/2\n",
    "            temp_rb_x, temp_rb_y = el[1]-temp_width/2, el[2]-temp_heigth/2\n",
    "            if temp_lt_x<=min_x and temp_lt_y<=min_y:\n",
    "                min_x, min_y= temp_lt_x,temp_lt_y\n",
    "            else if temp_rb_x>=max_x and temp_rb_y>=max_y:\n",
    "                max_x, max_y= temp_lt_x,temp_lt_y\n",
    "\n",
    "print(min_x, min_y,max_x, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import  Image, ImageDraw\n",
    "\n",
    "count = 0\n",
    "\n",
    "for gen_image in test_generator:\n",
    "    img = Image.fromarray(np.uint8((gen_image[0][0])*255))\n",
    "    img1 = ImageDraw.Draw(img)\n",
    "    x1,y1 = pred[count][0],pred[count][1]\n",
    "    x4,y4= pred[count][0] + pred[count][2], pred[count][1] + pred[count][3]\n",
    "    img1.rectangle([(x1,y1),(x4,y4)], outline =\"red\") \n",
    "    #img.show() \n",
    "    img.save(\"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/results/output\"+ str(count) + \".jpg\")\n",
    "    #print(gen_image[0][0].shape,pred[count])\n",
    "    count = count + 1\n",
    "    if count == 1000:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
