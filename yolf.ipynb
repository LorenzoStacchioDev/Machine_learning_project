{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, InputLayer, Flatten, BatchNormalization\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import keras_metrics\n",
    "import pandas\n",
    "import ast\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = \"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/train/\"\n",
    "validation_set = \"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/val/\"\n",
    "test_set = \"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pandas.read_csv(\"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/train/output.csv\")\n",
    "valid_df = pandas.read_csv(\"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/val/output.csv\")\n",
    "test_df = pandas.read_csv(\"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/test/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_id</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139981</td>\n",
       "      <td>139982.jpg</td>\n",
       "      <td>114</td>\n",
       "      <td>138</td>\n",
       "      <td>159</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172207</td>\n",
       "      <td>172208.jpg</td>\n",
       "      <td>86</td>\n",
       "      <td>42</td>\n",
       "      <td>112</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    image_id  x_1  y_1  width  height\n",
       "0      139981  139982.jpg  114  138    159     220\n",
       "1      172207  172208.jpg   86   42    112     155"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 164105 validated image filenames.\n",
      "Found 18234 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "IMG_SIZE = 224\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    brightness_range=[0.4,1.0])\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=train_set,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=[\"x_1\",\"y_1\",\"width\",\"height\"],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=validation_set,\n",
    "        x_col=\"image_id\",\n",
    "        y_col=[\"x_1\",\"y_1\",\"width\",\"height\"],\n",
    "        class_mode=\"raw\",\n",
    "        shuffle=True,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.samples/train_generator.batch_size\n",
    "step_size_valid = valid_generator.samples/valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224,224,3)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "          \n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(1,1), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=1024, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(2622, (1, 1)))\n",
    "\n",
    "#model.add(Conv2D(filters=4, kernel_size=(1,1)))\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "#model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_4_neurons_number = [int(round(x/(i+1),0)) for (x,i) in zip([2622]*2,\n",
    "                                           range(2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(rule_4_neurons_number[0], activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(rule_4_neurons_number[1], activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 224, 224, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 28, 28, 128)       32896     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 14, 14, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 14, 14, 256)       131328    \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 7, 7, 512)         524800    \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 7, 7, 512)         524800    \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 1, 1, 4096)        205524992 \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 1, 1, 2622)        10742334  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2622)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2622)              6877506   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2622)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1311)              3438753   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1311)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 5248      \n",
      "=================================================================\n",
      "Total params: 263,184,289\n",
      "Trainable params: 263,182,305\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multi_gpu_model(model, gpus=2) #parallelize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr = 1e-5), loss='mse', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/71 [==============================] - 46s 638ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[142759.9375, 0.0012065372429788113]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(valid_generator, steps=step_size_valid, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "642/641 [==============================] - 767s 1s/step - loss: 19165.6202 - accuracy: 0.7991 - val_loss: 17866.4941 - val_accuracy: 0.8098\n",
      "Epoch 2/100\n",
      "642/641 [==============================] - 788s 1s/step - loss: 16798.7198 - accuracy: 0.8092 - val_loss: 8826.1318 - val_accuracy: 0.8098\n",
      "Epoch 3/100\n",
      "642/641 [==============================] - 765s 1s/step - loss: 16229.5906 - accuracy: 0.8095 - val_loss: 19233.2578 - val_accuracy: 0.8098\n",
      "Epoch 4/100\n",
      "642/641 [==============================] - 767s 1s/step - loss: 15654.0811 - accuracy: 0.8095 - val_loss: 18899.7520 - val_accuracy: 0.8098\n",
      "Epoch 5/100\n",
      "642/641 [==============================] - 779s 1s/step - loss: 15072.4860 - accuracy: 0.8090 - val_loss: 6668.9395 - val_accuracy: 0.8072\n",
      "Epoch 6/100\n",
      "642/641 [==============================] - 779s 1s/step - loss: 14546.2964 - accuracy: 0.8072 - val_loss: 7542.3477 - val_accuracy: 0.7963\n",
      "Epoch 7/100\n",
      "642/641 [==============================] - 782s 1s/step - loss: 13937.6338 - accuracy: 0.8072 - val_loss: 5930.1455 - val_accuracy: 0.7362\n",
      "Epoch 8/100\n",
      "642/641 [==============================] - 774s 1s/step - loss: 13479.3186 - accuracy: 0.8054 - val_loss: 10890.5303 - val_accuracy: 0.8051\n",
      "Epoch 9/100\n",
      "642/641 [==============================] - 767s 1s/step - loss: 12731.1164 - accuracy: 0.8052 - val_loss: 10795.3770 - val_accuracy: 0.8078\n",
      "Epoch 10/100\n",
      "642/641 [==============================] - 767s 1s/step - loss: 11935.6685 - accuracy: 0.8046 - val_loss: 17468.6152 - val_accuracy: 0.7881\n",
      "Epoch 11/100\n",
      "642/641 [==============================] - 826s 1s/step - loss: 11350.8691 - accuracy: 0.8032 - val_loss: 8167.4438 - val_accuracy: 0.8034\n",
      "Epoch 12/100\n",
      "642/641 [==============================] - 783s 1s/step - loss: 10958.7621 - accuracy: 0.8024 - val_loss: 15399.5068 - val_accuracy: 0.8071\n",
      "Epoch 13/100\n",
      "642/641 [==============================] - 758s 1s/step - loss: 10347.6540 - accuracy: 0.8033 - val_loss: 12672.9932 - val_accuracy: 0.7859\n",
      "Epoch 14/100\n",
      "642/641 [==============================] - 771s 1s/step - loss: 9776.0899 - accuracy: 0.8036 - val_loss: 27215.1875 - val_accuracy: 0.7876\n",
      "Epoch 15/100\n",
      "642/641 [==============================] - 779s 1s/step - loss: 9360.7989 - accuracy: 0.8042 - val_loss: 23745.9160 - val_accuracy: 0.7940\n",
      "Epoch 16/100\n",
      "642/641 [==============================] - 770s 1s/step - loss: 8931.3939 - accuracy: 0.8051 - val_loss: 11915.0928 - val_accuracy: 0.7659\n",
      "Epoch 17/100\n",
      "642/641 [==============================] - 761s 1s/step - loss: 8607.8985 - accuracy: 0.8053 - val_loss: 14516.2822 - val_accuracy: 0.8025\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 18/100\n",
      "642/641 [==============================] - 762s 1s/step - loss: 7788.0488 - accuracy: 0.8098 - val_loss: 7649.5474 - val_accuracy: 0.7914\n",
      "Epoch 19/100\n",
      "642/641 [==============================] - 762s 1s/step - loss: 7501.0930 - accuracy: 0.8087 - val_loss: 18256.3613 - val_accuracy: 0.7942\n",
      "Epoch 20/100\n",
      "642/641 [==============================] - 764s 1s/step - loss: 7369.2211 - accuracy: 0.8092 - val_loss: 16851.3398 - val_accuracy: 0.7914\n",
      "Epoch 21/100\n",
      "642/641 [==============================] - 772s 1s/step - loss: 7250.9304 - accuracy: 0.8097 - val_loss: 11606.1377 - val_accuracy: 0.7867\n",
      "Epoch 22/100\n",
      "642/641 [==============================] - 762s 1s/step - loss: 7089.8052 - accuracy: 0.8097 - val_loss: 18829.3340 - val_accuracy: 0.7935\n",
      "Epoch 23/100\n",
      "642/641 [==============================] - 765s 1s/step - loss: 7019.5598 - accuracy: 0.8099 - val_loss: 28737.4297 - val_accuracy: 0.7937\n",
      "Epoch 24/100\n",
      "642/641 [==============================] - 758s 1s/step - loss: 6910.7877 - accuracy: 0.8109 - val_loss: 21491.1992 - val_accuracy: 0.7876\n",
      "Epoch 25/100\n",
      "642/641 [==============================] - 762s 1s/step - loss: 6885.2096 - accuracy: 0.8097 - val_loss: 18027.9434 - val_accuracy: 0.7910\n",
      "Epoch 26/100\n",
      "642/641 [==============================] - 761s 1s/step - loss: 6806.9080 - accuracy: 0.8119 - val_loss: 17920.8867 - val_accuracy: 0.7924\n",
      "Epoch 27/100\n",
      "642/641 [==============================] - 760s 1s/step - loss: 6742.3934 - accuracy: 0.8118 - val_loss: 12010.6318 - val_accuracy: 0.7802\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 28/100\n",
      "642/641 [==============================] - 764s 1s/step - loss: 6592.2438 - accuracy: 0.8121 - val_loss: 11305.2871 - val_accuracy: 0.7944\n",
      "Epoch 29/100\n",
      "642/641 [==============================] - 760s 1s/step - loss: 6585.0285 - accuracy: 0.8118 - val_loss: 46841.8711 - val_accuracy: 0.7964\n",
      "Epoch 30/100\n",
      "642/641 [==============================] - 755s 1s/step - loss: 6553.7769 - accuracy: 0.8126 - val_loss: 40936.4648 - val_accuracy: 0.7942\n",
      "Epoch 31/100\n",
      "642/641 [==============================] - 765s 1s/step - loss: 6634.4242 - accuracy: 0.8127 - val_loss: 29516.3809 - val_accuracy: 0.7921\n",
      "Epoch 32/100\n",
      "642/641 [==============================] - 766s 1s/step - loss: 6591.7625 - accuracy: 0.8129 - val_loss: 15548.3721 - val_accuracy: 0.7953\n",
      "Epoch 33/100\n",
      "642/641 [==============================] - 766s 1s/step - loss: 6563.0713 - accuracy: 0.8123 - val_loss: 11381.8037 - val_accuracy: 0.7921\n",
      "Epoch 34/100\n",
      "642/641 [==============================] - 771s 1s/step - loss: 6604.5436 - accuracy: 0.8128 - val_loss: 12908.1465 - val_accuracy: 0.7943\n",
      "Epoch 35/100\n",
      "642/641 [==============================] - 784s 1s/step - loss: 6532.9892 - accuracy: 0.8123 - val_loss: 17374.2891 - val_accuracy: 0.7966\n",
      "Epoch 36/100\n",
      "642/641 [==============================] - 763s 1s/step - loss: 6539.4935 - accuracy: 0.8127 - val_loss: 13874.0312 - val_accuracy: 0.7924\n",
      "Epoch 37/100\n",
      "642/641 [==============================] - 761s 1s/step - loss: 6515.8298 - accuracy: 0.8138 - val_loss: 10124.9932 - val_accuracy: 0.7936\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 38/100\n",
      "642/641 [==============================] - 769s 1s/step - loss: 6520.3049 - accuracy: 0.8118 - val_loss: 5675.9385 - val_accuracy: 0.7934\n",
      "Epoch 39/100\n",
      "642/641 [==============================] - 765s 1s/step - loss: 6511.7272 - accuracy: 0.8125 - val_loss: 11168.5107 - val_accuracy: 0.7939\n",
      "Epoch 40/100\n",
      "642/641 [==============================] - 755s 1s/step - loss: 6508.5542 - accuracy: 0.8127 - val_loss: 14321.8252 - val_accuracy: 0.7928\n",
      "Epoch 41/100\n",
      "642/641 [==============================] - 761s 1s/step - loss: 6489.8920 - accuracy: 0.8128 - val_loss: 4317.1572 - val_accuracy: 0.7922\n",
      "Epoch 42/100\n",
      "642/641 [==============================] - 775s 1s/step - loss: 6497.0954 - accuracy: 0.8121 - val_loss: 21447.4609 - val_accuracy: 0.7946\n",
      "Epoch 43/100\n",
      "642/641 [==============================] - 763s 1s/step - loss: 6511.7251 - accuracy: 0.8126 - val_loss: 11725.0342 - val_accuracy: 0.7951\n",
      "Epoch 44/100\n",
      "642/641 [==============================] - 785s 1s/step - loss: 6513.3148 - accuracy: 0.8123 - val_loss: 19401.6074 - val_accuracy: 0.7944\n",
      "Epoch 45/100\n",
      "642/641 [==============================] - 771s 1s/step - loss: 6515.1719 - accuracy: 0.8128 - val_loss: 14909.9072 - val_accuracy: 0.7941\n",
      "Epoch 46/100\n",
      "642/641 [==============================] - 767s 1s/step - loss: 6525.0829 - accuracy: 0.8124 - val_loss: 14490.6348 - val_accuracy: 0.7906\n",
      "Epoch 47/100\n",
      "642/641 [==============================] - 769s 1s/step - loss: 6481.6974 - accuracy: 0.8123 - val_loss: 12129.4336 - val_accuracy: 0.7938\n",
      "Epoch 48/100\n",
      "642/641 [==============================] - 766s 1s/step - loss: 6547.5636 - accuracy: 0.8130 - val_loss: 11241.0547 - val_accuracy: 0.7946\n",
      "Epoch 49/100\n",
      "642/641 [==============================] - 758s 1s/step - loss: 6459.1325 - accuracy: 0.8133 - val_loss: 7613.5161 - val_accuracy: 0.7943\n",
      "Epoch 50/100\n",
      "642/641 [==============================] - 775s 1s/step - loss: 6515.8300 - accuracy: 0.8127 - val_loss: 21059.0898 - val_accuracy: 0.7944\n",
      "Epoch 51/100\n",
      "642/641 [==============================] - 759s 1s/step - loss: 6529.8542 - accuracy: 0.8126 - val_loss: 10479.8545 - val_accuracy: 0.7948\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 52/100\n",
      "642/641 [==============================] - 761s 1s/step - loss: 6489.3800 - accuracy: 0.8128 - val_loss: 11782.3496 - val_accuracy: 0.7925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "642/641 [==============================] - 782s 1s/step - loss: 6512.6560 - accuracy: 0.8126 - val_loss: 5445.5586 - val_accuracy: 0.7897\n",
      "Epoch 54/100\n",
      "642/641 [==============================] - 776s 1s/step - loss: 6486.5202 - accuracy: 0.8126 - val_loss: 17790.7949 - val_accuracy: 0.7963\n",
      "Epoch 55/100\n",
      "642/641 [==============================] - 766s 1s/step - loss: 6490.3866 - accuracy: 0.8119 - val_loss: 15344.1807 - val_accuracy: 0.7947\n",
      "Epoch 56/100\n",
      "642/641 [==============================] - 769s 1s/step - loss: 6523.0344 - accuracy: 0.8125 - val_loss: 28550.1504 - val_accuracy: 0.7943\n",
      "Epoch 57/100\n",
      "642/641 [==============================] - 767s 1s/step - loss: 6687.9453 - accuracy: 0.8129 - val_loss: 4888.3965 - val_accuracy: 0.7935\n",
      "Epoch 58/100\n",
      "642/641 [==============================] - 777s 1s/step - loss: 6505.5056 - accuracy: 0.8120 - val_loss: 9131.7021 - val_accuracy: 0.7934\n",
      "Epoch 59/100\n",
      "642/641 [==============================] - 751s 1s/step - loss: 6484.6694 - accuracy: 0.8133 - val_loss: 11787.6396 - val_accuracy: 0.7928\n",
      "Epoch 60/100\n",
      "642/641 [==============================] - 764s 1s/step - loss: 6510.4420 - accuracy: 0.8130 - val_loss: 7070.3335 - val_accuracy: 0.7954\n",
      "Epoch 61/100\n",
      "642/641 [==============================] - 766s 1s/step - loss: 6526.1438 - accuracy: 0.8127 - val_loss: 28494.9219 - val_accuracy: 0.7943\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 62/100\n",
      "642/641 [==============================] - 770s 1s/step - loss: 6546.5720 - accuracy: 0.8128 - val_loss: 21745.2891 - val_accuracy: 0.7935\n",
      "Epoch 63/100\n",
      "642/641 [==============================] - 765s 1s/step - loss: 6498.3052 - accuracy: 0.8133 - val_loss: 10331.8887 - val_accuracy: 0.7936\n",
      "Epoch 64/100\n",
      "642/641 [==============================] - 764s 1s/step - loss: 6497.1222 - accuracy: 0.8128 - val_loss: 8975.0312 - val_accuracy: 0.7935\n",
      "Epoch 65/100\n",
      "642/641 [==============================] - 772s 1s/step - loss: 6489.9800 - accuracy: 0.8133 - val_loss: 5656.1680 - val_accuracy: 0.7960\n",
      "Epoch 66/100\n",
      "642/641 [==============================] - 764s 1s/step - loss: 6513.6584 - accuracy: 0.8124 - val_loss: 4063.8201 - val_accuracy: 0.7943\n",
      "Epoch 67/100\n",
      "642/641 [==============================] - 774s 1s/step - loss: 6518.7978 - accuracy: 0.8127 - val_loss: 9763.4082 - val_accuracy: 0.7929\n",
      "Epoch 68/100\n",
      "642/641 [==============================] - 774s 1s/step - loss: 6521.0416 - accuracy: 0.8123 - val_loss: 12976.5215 - val_accuracy: 0.7947\n",
      "Epoch 69/100\n",
      "642/641 [==============================] - 758s 1s/step - loss: 6543.6369 - accuracy: 0.8129 - val_loss: 22483.2793 - val_accuracy: 0.7913\n",
      "Epoch 70/100\n",
      "642/641 [==============================] - 770s 1s/step - loss: 6495.4774 - accuracy: 0.8131 - val_loss: 15585.9521 - val_accuracy: 0.7946\n",
      "Epoch 71/100\n",
      "642/641 [==============================] - 774s 1s/step - loss: 6494.8788 - accuracy: 0.8135 - val_loss: 7929.4463 - val_accuracy: 0.7959\n",
      "Epoch 72/100\n",
      "642/641 [==============================] - 767s 1s/step - loss: 6493.5457 - accuracy: 0.8122 - val_loss: 15932.0420 - val_accuracy: 0.7974\n",
      "Epoch 73/100\n",
      "642/641 [==============================] - 767s 1s/step - loss: 6525.0032 - accuracy: 0.8126 - val_loss: 24409.8203 - val_accuracy: 0.7962\n",
      "Epoch 74/100\n",
      "642/641 [==============================] - 773s 1s/step - loss: 6493.2776 - accuracy: 0.8129 - val_loss: 13860.2734 - val_accuracy: 0.7946\n",
      "Epoch 75/100\n",
      "642/641 [==============================] - 767s 1s/step - loss: 6505.6627 - accuracy: 0.8141 - val_loss: 4874.8188 - val_accuracy: 0.7944\n",
      "Epoch 76/100\n",
      "642/641 [==============================] - 783s 1s/step - loss: 6611.8269 - accuracy: 0.8129 - val_loss: 11746.0713 - val_accuracy: 0.7943\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "Epoch 77/100\n",
      "642/641 [==============================] - 770s 1s/step - loss: 6504.8304 - accuracy: 0.8123 - val_loss: 19561.0215 - val_accuracy: 0.7928\n",
      "Epoch 78/100\n",
      "642/641 [==============================] - 772s 1s/step - loss: 6537.1346 - accuracy: 0.8132 - val_loss: 5915.0718 - val_accuracy: 0.7941\n",
      "Epoch 79/100\n",
      "642/641 [==============================] - 764s 1s/step - loss: 6491.7344 - accuracy: 0.8137 - val_loss: 8989.4697 - val_accuracy: 0.7969\n",
      "Epoch 80/100\n",
      "642/641 [==============================] - 764s 1s/step - loss: 6556.7842 - accuracy: 0.8134 - val_loss: 5981.6460 - val_accuracy: 0.7943\n",
      "Epoch 81/100\n",
      "642/641 [==============================] - 772s 1s/step - loss: 6520.0895 - accuracy: 0.8128 - val_loss: 5917.7354 - val_accuracy: 0.7915\n",
      "Epoch 82/100\n",
      "642/641 [==============================] - 764s 1s/step - loss: 6528.7705 - accuracy: 0.8134 - val_loss: 26058.8887 - val_accuracy: 0.7939\n",
      "Epoch 83/100\n",
      "642/641 [==============================] - 768s 1s/step - loss: 6507.9079 - accuracy: 0.8132 - val_loss: 22383.2090 - val_accuracy: 0.7928\n",
      "Epoch 84/100\n",
      "642/641 [==============================] - 767s 1s/step - loss: 6514.6476 - accuracy: 0.8122 - val_loss: 10208.5205 - val_accuracy: 0.7948\n",
      "Epoch 85/100\n",
      "642/641 [==============================] - 756s 1s/step - loss: 6535.4021 - accuracy: 0.8125 - val_loss: 4110.9155 - val_accuracy: 0.7942\n",
      "Epoch 86/100\n",
      "642/641 [==============================] - 770s 1s/step - loss: 6511.9463 - accuracy: 0.8130 - val_loss: 13664.8789 - val_accuracy: 0.7966\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 87/100\n",
      "642/641 [==============================] - 780s 1s/step - loss: 6521.1717 - accuracy: 0.8130 - val_loss: 12584.4980 - val_accuracy: 0.7966\n",
      "Epoch 88/100\n",
      "642/641 [==============================] - 776s 1s/step - loss: 6504.7377 - accuracy: 0.8132 - val_loss: 62503.0234 - val_accuracy: 0.7930\n",
      "Epoch 89/100\n",
      "642/641 [==============================] - 763s 1s/step - loss: 6497.5309 - accuracy: 0.8130 - val_loss: 9496.8350 - val_accuracy: 0.7937\n",
      "Epoch 90/100\n",
      "642/641 [==============================] - 769s 1s/step - loss: 6525.4165 - accuracy: 0.8130 - val_loss: 19821.2500 - val_accuracy: 0.7951\n",
      "Epoch 91/100\n",
      "642/641 [==============================] - 753s 1s/step - loss: 6555.3102 - accuracy: 0.8132 - val_loss: 14082.1855 - val_accuracy: 0.7964\n",
      "Epoch 92/100\n",
      "331/641 [==============>...............] - ETA: 5:50 - loss: 6534.5689 - accuracy: 0.8147"
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min')\n",
    "mcp_save = ModelCheckpoint('yolf.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min')\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, epochs=100, steps_per_epoch=step_size_train, validation_data=valid_generator, validation_steps=step_size_valid, verbose=1, callbacks=[mcp_save, earlyStopping, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training accuracy')\n",
    "plt.plot(val_acc, label='Validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim([min(plt.ylim()),500])\n",
    "plt.title('Training and Validation accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,20000])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                    directory=test_set,\n",
    "                                    x_col=\"image_id\",\n",
    "                                    y_col=[\"x_1\",\"y_1\",\"width\",\"height\"],\n",
    "                                    class_mode=\"raw\",\n",
    "                                    shuffle=True,\n",
    "                                    target_size=(224, 224),\n",
    "                                    batch_size=BATCH_SIZE)\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n / test_generator.batch_size \n",
    "\n",
    "\n",
    "#CHANGE PARALLEL MODEL\n",
    "pred=model.predict_generator(test_generator,  steps=STEP_SIZE_TEST,  verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import  Image, ImageDraw\n",
    "\n",
    "count = 0\n",
    "\n",
    "for gen_image in test_generator:\n",
    "    img = Image.fromarray(np.uint8((gen_image[0][0])*255))\n",
    "    img1 = ImageDraw.Draw(img)\n",
    "    x1,y1 = pred[count][0],pred[count][1]\n",
    "    x4,y4= pred[count][0] + pred[count][2], pred[count][1] + pred[count][3]\n",
    "    img1.rectangle([(x1,y1),(x4,y4)], outline =\"red\") \n",
    "    #img.show() \n",
    "    img.save(\"/home/lorenzo.stacchio/ML/Machine_learning_project/dataset/NUOVO/results/output\"+ str(count) + \".jpg\")\n",
    "    #print(gen_image[0][0].shape,pred[count])\n",
    "    count = count + 1\n",
    "    if count == 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
